https://github.com/JosephZhu1983/java-common-mistakes



# 1.使用了并发工具类库，线程安全就高枕无忧了吗

1.ThreadLocal内存泄漏，原因是tomcat线程复用，快速复现可以通过设置tomcat核心线程数为1，解决方案在finally代码块中显式清除threadlocal中的数据

2.ConcurrentHashMap只能保证提供的原子性读写操作是线程安全的，对于如putAll这样的聚合操作仍是线程不安全的，在多线程环境下需要加锁

3.利用ConcurrentHashMap的computeIfAbsent（底层为CAS）来做符合逻辑操作，这虽然不是原子性操作，但是是线程安全的，配合LongAdder可以用于多线程环境下的计数器

4.CopyOnWriteArrayList虽然是线程安全的ArrayList，但是其实现方式是：每次修改数据时都会复制一份数据出来，这样读数据时不需要加锁，并保证数据最终一致性，所以有明显的适用场景即读多写少，或者强调无锁读的场景，在大量写的场景时会严重影响性能



# 2.代码加锁：不要让“锁”事成为烦心事

1.在业务代码中加锁，除了考虑锁的粒度，还可以从以下角度优化：

- 对于读写比例差异明细的场景，考虑使用ReentrantReadWriteLock细化区分读写锁
- 考虑使用StampedLock的乐观锁特性
- 不要轻易开启公平锁特性，会影响性能

2.业务逻辑中有多把锁时要考虑死锁问题，通常的规避方案是避免无限等待（如设置等待时间上限）和循环等待（如给获取锁排序）



# 3.线程池：业务代码最常用也最容易犯错的组件

1.线程池的声明需要手动进行，newFixedThreadPool的工作队列使用了一个无界队列，在任务较多且执行慢的情况下，队列会快速挤压，导致OOM；而newCachedThreadPool会无限制的创建工作线程，同样会导致OOM



2.线程池默认的工作行为：

- 不会初始化corePoolSize个线程，而是有任务来了才创建工作线程
- 当核心线程满了之后不会立即扩容线程池，而是把任务堆积到工作队列中
- 当工作队列满了后扩容线程池，直到线程个数达到maximumPoolSize
- 如果队列已满并已达到最大线程数后还有任务进来，按照拒绝策略处理
- 当线程数大于核心线程数时，线程等待keepAliveTime后还是没有任务需要处理的话，收缩线程到核心线程数

也可以通过一些手段来改变这些默认行为 如：

- 声明线程池后立即调用prestartAllCoreThreads方法来启动所有核心线程
- 传入true给allowCoreThreadTimeOut方法，让核心线程同样在空闲时间被回收

线程池总是先用工作队列来存放来不及处理的任务，满了之后再扩容线程数，当工作队列设置的很大时，最大线程数这个参数基本不起作用，因为队列很难满，或者满了再去扩容已经于事无补，但是把工作队列设置的很小时，可能又很容易触发拒绝策略



可以改造线程池来实现：优先开启更多的线程，而把队列当做后备方案

大致思路：

- 由于线程池在工作队列满了的情况下无法入队，会扩容线程池，那么可以重写队列的offer方法，造成这个队列已满的假象
- 由于重写了这一方法，在达到最大线程数线程池会触发拒绝策略，所以需要自定义一个拒绝策略，这个时候再把任务真正插入队列

**tomcat中就有类似的实现**



3.明确线程池是否需要复用，还是每次业务逻辑开始，就开启一个线程池，这种方式是较为不合理的，通常情况下线程池都是复用的



4.复用线程池不代表始终使用同一个线程池，可以根据任务的性质来选用不同的线程池，IO密集型任务和CPU计算密集型任务的偏好是不同的

- 对于IO密集任务，可以考虑更多的线程数，而不需要太大的队列
- 对于CPU密集任务，线程数量不宜过多，可以设置为CPU核心数量左右的线程数量，需要较长的队列来做缓冲

如果希望减少任务间的互相干扰，考虑按需使用隔离的线程池



5.监控线程池是非常重要的



# 4.连接池：别让连接池帮了倒忙

1.鉴别客户端SDK是否基于连接池，如果SDK没有使用连接池，而是直接使用TCP连接，首先会有较大的开销，其次因为TCP基于字节流，在多线程环境下若对同一连接进行复用，可能会产生线程安全问题

- 连接池和连接分离的API：通过一个XXXPool获得XXXConnection
- 内部带有连接池的API：对外提供一个XXXClient类，这个类内部维护了线程池，使用时无需考虑连接的获取和归还
- 非连接池的API：一般命名为XXXConnection，每次使用需要创建和断开连接，且通常是线程不安全的，使用时可以考虑自己封装一个线程池



2.多线程使用Jedis时，如果复用Jedis对象，其实是复用底层的RedisOutPutStream来写入命令，无法保证整条命令以一个原子操作写入Socket，也无法确保写入、读取前没有其他数据写到远端，应该通过Jedis提供的线程安全的类JedisPool来获取Jedis实例，JedisPool可以声明为static在多个线程之间共享，扮演连接池的角色，使用时通过try-with-resources从JedisPool获取和归还Jedis实例。



3.程序退出时，可以通过shutdownhook在程序退出之前关闭连接池资源

![image-20210326101550520](极客时间-Java业务开发常见错误100.assets/image-20210326101550520.png)



4.使用池时，一定要复用池，否则其使用代价会比每次创建单一对象更大，复用方式可以把XXXClient声明为static，只创建一次，并且在JVM关闭前通过addShutDownHook钩子关闭连接池



5.在Spring中可以把XXXClient资源定义为Bean，通过@PostConstruct和@PreDestory来加载和释放资源



6.合理配置连接池参数



# 5.HTTP调用：你考虑到超时、重试、并发了吗？

1.网络请求需要考虑的三点：

- 框架设置的默认超时是否合理
- 考虑到网络的不稳定，可以在超时后进行重试，但是需要考虑接口的幂等性设计
- 考虑框架是否会想浏览器一样限制并发连接数，以免在高并发情况下HTTP调用的并发限制成为瓶颈



对于HTTP调用，虽然应用层走的是HTTP协议，但网络层面始终是TCP/IP协议，作为一个面向连接的协议，在传输数据前需要建立连接，几乎所有的网络框架都会提供这样两个超时参数：

- 连接超时参数ConnectTimeout，让用户配置建立连接的最长等待时间
- 读取超时参数ReadTimeout，从Socket上读取数据的最长等待时间



**对于第一个参数：连接超时参数，需要注意以下点：**

1. 连接超时参数不需要配置的特别长，一般来说TCP三次握手的时间在毫秒级到秒级，如果很久无法建立连接，可能是网络或者防火墙的配置问题，这种情况下如果几秒没连上，那么可能永远也连不上了，所以这个参数可以设置到1~5秒，失败时也可以快速失败
2. 排查连接超时问题，要搞清楚连接的是哪里，主要注意的是如果使用了nginx反向代理，那么实际上客户端连接的是nginx而不是服务端



**对于第二个参数：读取超时参数，需要注意以下点：**

1. 出现了读取超时，服务端的执行并不会中断
2. 读取超时并不只是数据传输的最长耗时，实际上其中的（绝大部分）时间，都是服务端处理业务逻辑的时间
3. 对于同步调用，如果超时时间很长，那么在等待服务端返回数据的同时，客户端（通常是Tomcat线程）也在等待，当下游服务出现大量超时的情况，客户端也会被迫创建大量线程，可能崩溃，对于定时任务/异步任务来说，读取超时参数可以配置的长一些，而对于面向客户响应或者是微服务的同步接口调用，通常不会设置超过30s的读取超时，针对不同的下游服务的处理时间不同，可能还需要为不同的服务端接口设置不同的客户端读取超时时间



**Feign和Ribbon的超时时间知识点：**

1. 默认情况下Feign的读取超时是1s，有点短
2. 要配置Feign的读取超时，就必须同时配置连接超时参数，才能生效
3. 针对单独的Feign Client设置超时时间，可以覆盖全局的超时
4. 除了配置Feign的超时参数，也可以配置Ribbon的超时参数，同时配置的话以Feign为准



**Ribbon的自动重试请求：**

Ribbon对于Get请求，在出现问题时（如读取超时），Ribbon会自动重试一次



**并发限制了爬虫的抓取能力**

1.对于Java自带的HttpClient，他对于同一个主机/域名的最大并发请求数为2，这个默认值太小，可能会限制效率

2.主机整体最大并发数为20，也就是HttpClient整体的并发度



# 6.20%的业务代码的Spring声明式事务，可能都没处理正确

1.注意Spring事务的生效规则

- @Transactional注解除非在特殊配置（如使用AspectJ静态织入实现AOP），否则**只有定义在public方法上的@Transactional才能生效**，原因是Spring默认通过动态代理的方式实现AOP，而private方法无法被代理到，Spring自然也无法动态增强事务处理逻辑
- **必须通过代理过的类 从外部 调用目标方法才能生效** 如果在本Service中使用一个未打注解的方法调用一个打事务注解的方法，事务无法生效，因为通过this自调用，是没有机会走到Spring的代理类的，可以用注入自身的例子来尝试，注入自身实际上注入的是代理类



2.注意事务生效后回滚的规则

- 只有异常**传播出了**被标记@Transactional注解的方法，事务才能回滚，如果希望自己捕获异常进行处理，那么异常就不会被传播出方法，此时应该在catch代码块中使用TransactionAspectSupport.currentTransactionStatus().setRollbackOnly()方法来手动回滚
- 默认情况下，出现RuntimeException（非受检异常）或Error时，Spring才会进行回滚，可以通过设置@Transactional(rollbackFor = Exception.class)来使遇到所有异常都回滚事务



3.如果涉及多次数据库操作，并希望将它们作为独立的事务进行提交或回滚，需要进一步细化配置事务传播方式，也就是@Transactional注解的Propagation属性



# 7.数据库索引：索引并不是万能药

1.InNoDB是如何存储数据的

以页为单位保存在磁盘中，页大小一般为16KB

各个数据页组成一个双向链表，每个数据页的记录按照主键顺序组成单向联表，每个数据页中有一个页目录，可以通过页目录进行二分查找，页目录通过槽把记录分成不同的小组，槽指向小组的第一条记录



2.聚簇索引和二级索引

**聚簇索引**

叶子节点会保存数据，由于数据在物理上只会保存一份，所以包含实际数据的聚簇索引只有一个，默认情况下会使用主键作为聚簇索引的索引键，没有主键则会使用第一个不包含NULL值的唯一列



**二级索引**

为了实现非主键字段的快速搜索，引出了二级索引，也叫做非聚簇索引/辅助索引，同样使用B+树，索引键是自定义的业务属性，而叶子节点中存储的不再是实际数据，**而是主键**，获取主键值后再去聚簇索引中获得数据行，这一过程叫做**回表**



3.额外创建二级索引的代价

- 维护代价：N个二级索引就是N棵B+树，对数据的增删改还要修改这N个二级索引
- 空间代价：占用N棵树的空间
- 回表代价：只使用二级索引无法找到数据，还是需要通过聚簇索引来回表



如果索引本身包含需要查询的所有数据列，那么就不需要回表就可以拿到需要的所有数据，这种情况叫做**覆盖索引**



4.关于索引开销的最佳实践

- 不需要一开始就创建索引，而是明确业务场景/数据量足够大导致查询变慢时在针对需要的字段创建索引
- 尽量索引轻量级的字段，比如可以索引int字段就不要索引varchar字段，索引字段也可以是部分前缀，创建索引的时候指定字段索引的长度
- 不要使用SELECT * ，而是只取出必要的字段，可以考虑使用联合索引来做覆盖索引，避免回表



5.索引失效的情况分析

- 索引只能匹配列前缀，比如使用LIKE的时候，搜索指定后缀的情况无法走索引，指定前缀则可以走索引，所以如果希望按照后缀搜索也走索引的话，可以把数据反过来存，用的时候再倒过来
- 条件涉及函数操作无法走索引
- 联合索引只能匹配左边的列，优化器会把多个where条件按照索引顺序排序，但是范围查询会使联合索引断开，这是因为在一个范围值确定后，后面的记录等同于全表扫描了



6.数据库基于成本决定是否走索引

Mysql在查询数据之前，会对多种可能的方案做执行计划，然后对成本分析决定走哪一个计划

成本主要包括IO成本和CPU成本

- IO成本指的是从磁盘把数据加载到内存的成本，默认情况下读取1个数据页的成本为1
- CPU成本是判断数据与条件是否相等的CPU操作的成本，默认情况下为0.2

MySQL会存储行数和数据长度（用于计算页数量）来计算全表扫描的成本

MySQL选择索引，并不是按照where条件中列的顺序进行的

同样即使列有索引，甚至可能有多个索引方案，MySQL也可能不走索引



# 8. 判等问题：程序里如何确定你就是你？



对于自定义类型，如果类型需要参与判等，那么需要同时实现equals和hashCode方法，并确保逻辑一致

默认的hashCode方法是native方法

```javascript
Thread state combined with xorshift (https://en.wikipedia.org/wiki/Xorshift)
```

生成一个线程状态和随机数的结合

如果要自定义hasiCode，可以直接使用Objects.hash方法来实现，也可以通过IDE的代码生成功能或者Lombok来生成

如果类型也要参与比较，那么compareTo方法的逻辑同样需要和equals、hashCode方法一致



Lombok的@EqualsAndHashCode注解实现equals和hashCode的时候，默认使用所有非static、非transient的字段，且不考虑父类，可以使用@EqualsAndHashCode.Exclude来排除一些字段，并设置callSuper = true来让子类的equals和hashCode调用父类的相应方法



# 9. 数值计算：注意精度、舍入和溢出问题

1.直接使用浮点数参与运算会丢失精度



**2.使用BigDecimal表示和计算浮点数，务必使用字符串的构造方法来初始化BigDecimal**，如果只有Double类型的话，可以使用BigDecimal.valueOf方法



3.**浮点数的字符串格式化也要通过BigDecimal进行**



4.**对于BigDecimal，如果用equals来做判等，会比较小数位长度，比如1.0和1是不相等的**，可以用compareTo方法来比较value，

这一点在使用HashSet/HashMap的时候也会出现问题，解决办法有两个

- 使用TreeSet方法替换HashSet，TreeSet不使用hashCode和equals来比较元素，而是使用compareTo
- 把BigDecimal存入HashSet或HashMap前，先试用stripTrailiingZeros去掉尾部的0，比较的时候也去掉



5.注意数值溢出问题，超过int/long等最大值

- 用Math类的addExact/subtractExact等方法进行数值运算，这些方法会在数值溢出时主动抛出RuntimeException
- 使用大数类BigInteger



# 10. 集合类：坑满地的List列表操作

1.不能直接使用Arrays.asList来转换**基本类型数组** 可以把它转换为包装类的数组 或是使用Arrays.stream(int数组).boxed().collect(Collectors.toList())



2.**使用Arrays.asList返回的List不支持增删操作，并且对元素的修改会影响原数组**，这是因为Arrays.asList返回的List并不是java.util.ArrayList，而是Arrays的内部类ArrayList，这个内部类不支持增删操作，并且直接使用了原始的数组，所以对这个ArrayList的修改会影响到原数组，修复的方式就是用一个new ArrayList(Arrays.asList(xxx))来重新初始化一个ArrayList



